{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dsNDWRHznMzI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#process : images(input_dim) -> hidden dim -> mean and std deviation vectors -> reparametrization -> latent dimension -> output_dim\n",
        "class VariationalAutoEncoder(nn.Module):\n",
        "  def __init__(self,input_dim, h_dim = 200,z_dim = 20): #h_dim:hidden_dimension\n",
        "    super().__init__()\n",
        "\n",
        "    #encoder\n",
        "    self.img_2hid = nn.Linear(input_dim,h_dim) #taking input image into a hidden dimension\n",
        "    self.hid_2mu = nn.Linear(h_dim,z_dim) #z_dim is dimension of mu vector or std deviation vector or the latent vector (all 3 have the same dim)\n",
        "    self.hid_2sigma = nn.Linear(h_dim,z_dim) #for sd vector\n",
        "\n",
        "    #reparamterization will be taken care of later(in the forward class).for now,assuming reparamaterization is done,we start from the latent vector in the decoder\n",
        "\n",
        "    #decoder\n",
        "    self.z_2hid = nn.Linear(z_dim,h_dim)\n",
        "    self.hid_2img = nn.Linear(h_dim,input_dim)\n",
        "\n",
        "\n",
        "\n",
        "  def encode(self,x): #q_phi(z|x)\n",
        "    h = self.relu(self.img_2hid(x)) #mapping input into hidden dim followed by relu activation\n",
        "    mu,sigma = self.hid_2mu(h),self.hid_2sigma(h) #?) why not ReLu here\n",
        "    return mu,sigma\n",
        "  \n",
        "  def decode(self,z): #p_theta(x|z) again assuming we already have the latent vector z\n",
        "    h = F.relu(self.z_2hid(z))\n",
        "    img = self.hid2img(h)\n",
        "    img = torch.sigmoid(img) #this step is specifically for our use-case,that is MNIST dataset,which assumes the pixel values are in b/w 0 and 1\n",
        "    return img\n",
        "\n",
        "  def forward(self,x,z):\n",
        "    #encode\n",
        "    mu,sigma = self.encode(x)\n",
        "    #now we apply reparamterization\n",
        "    epsilon = torch.rand_like(sigma)\n",
        "    z_reparametrized = mu+sigma*epsilon\n",
        "    #decode\n",
        "    x_reconstructed = self.decode(z_reparametrized)\n",
        "    return x_reconstructed,mu,sigma #remember that we need this mu and sigma to compute the loss functions (especially while computing the KL divergence)"
      ],
      "metadata": {
        "id": "AProO9V9oKmg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == \"__main__\":\n",
        "#  x = torch.randn(4,28*28) #batch_size = 4 and 28*28 images\n",
        "#  vae = VariationalAutoEncoder(input_dim = 784) #input dim is 28*28 flattened as an input vector. The other two paramters are already initialised above"
      ],
      "metadata": {
        "id": "_IxHZY6svssY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "INPUT_DIM = 784\n",
        "Z_DIM = 20\n",
        "H_DIM = 200\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LR_RATE = 3e-4"
      ],
      "metadata": {
        "id": "HGesrnzZLbnu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import torchvision.datasets as datasets  \n",
        "from torch.utils.data import DataLoader  "
      ],
      "metadata": {
        "id": "nnDeZyoKL6w0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading\n",
        "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "qkF3Oy1ELco1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train function\n",
        "def train(num_epochs, model, optimizer, loss_fn):\n",
        "    # Start training\n",
        "    for epoch in range(num_epochs):\n",
        "        loop = tqdm(enumerate(train_loader))\n",
        "        for i, (x, y) in loop:\n",
        "            # Forward pass\n",
        "            x = x.to(device).view(-1, INPUT_DIM)\n",
        "            x_reconst, mu, sigma = model(x)\n",
        "\n",
        "            # loss, formulas from https://www.youtube.com/watch?v=igP03FXZqgo&t=2182s\n",
        "            reconst_loss = loss_fn(x_reconst, x)\n",
        "            kl_div = - torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
        "\n",
        "            # Backprop and optimize\n",
        "            loss = reconst_loss + kl_div\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "iS1CuGl1Lg_m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, optimizer, loss\n",
        "model = VariationalAutoEncoder(INPUT_DIM, Z_DIM).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
        "loss_fn = nn.BCELoss(reduction=\"sum\")\n",
        "\n",
        "# Run training\n",
        "train(NUM_EPOCHS, model, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "JVfbhN0NMtLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(digit, num_examples=1):\n",
        "\n",
        "#    Generates (num_examples) of a particular digit.\n",
        "#   Specifically we extract an example of each digit,\n",
        "#    then after we have the mu, sigma representation for\n",
        "#    each digit we can sample from that.\n",
        "\n",
        "#    After we sample we can run the decoder part of the VAE\n",
        "#    and generate examples.\n",
        "\n",
        "    images = []\n",
        "    idx = 0\n",
        "    for x, y in dataset:\n",
        "        if y == idx:\n",
        "            images.append(x)\n",
        "            idx += 1\n",
        "        if idx == 10:\n",
        "            break\n",
        "\n",
        "    encodings_digit = []\n",
        "    for d in range(10):\n",
        "        with torch.no_grad():\n",
        "            mu, sigma = model.encode(images[d].view(1, 784))\n",
        "        encodings_digit.append((mu, sigma))\n",
        "\n",
        "    mu, sigma = encodings_digit[digit]\n",
        "    for example in range(num_examples):\n",
        "        epsilon = torch.randn_like(sigma)\n",
        "        z = mu + sigma * epsilon\n",
        "        out = model.decode(z)\n",
        "        out = out.view(-1, 1, 28, 28)\n",
        "        save_image(out, f\"generated_{digit}_ex{example}.png\")\n"
      ],
      "metadata": {
        "id": "SToWgAy3Lq9v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}